# Big picture {#meta-big-picture}

```{r, include = FALSE}
source("common.R")
```
## Introduction

Metaprogramming is the hardest topic in this book because it brings together many formerly unrelated topics and forces you grapple with issues that you probably haven't thought about before. You'll also need to learn a lot of new vocabulary, and at first it will seem like every new term is defined by three other terms that you haven't heard of. Even if you're an experienced programmer in another language, your existing skills are unlikely to be much help as few modern popular languages expose the level of metaprogramming that R provides.

So don't be surprised if you're frustrated or confused at first; this is a natural part of the process that happens to everyone! But I think it's easier to learn metaprogramming now than it's ever been before. Over the last few years, the theory and tools have matured substantially, providing a strong theoretical foundation paired with tools that allow you to solve common problems.

To make it easier to learn the details of metaprogramming, this chapter shows you the big picture, briefly introducing the main concepts and how they fit together. 

### Outline {-}

Each section in this chapter introduces one big new idea:

* Section \@ref(code-data): Code is data; captured code is called an expression.
  
* Section \@ref(code-tree): Code has a tree-like structure called an 
  abstract syntax tree.

* Section \@ref(coding-code): Code can create new expressions programmatically.

* Section \@ref(eval-intro): To "execute" code, you evaluate an expression in 
  an environment.

* Section \@ref(eval-funs): You can customise evaluation by supplying custom
  functions in a new environment.

* Section \@ref(eval-data): You can also customise evaluation by supplying a 
  data mask, which blurs the line between environments and data frames.

* Section \@ref(quosure-intro): All this is made simpler (and more correct) 
  with a new data structure called the quosure.

### Prerequisites {-}

This chapter uses introduces the big ideas using rlang, you'll learn the base equivalents in later chapters. We'll also use the lobstr package to explore the tree structure of code.

```{r setup}
library(rlang)
library(lobstr)
```

Make sure that you're also familiar with the environment (Section \@ref(env-basics)) and data frame (Section \@ref(tibble)) data structures.

## Code is data {#code-data}

The first big idea is that code is data: you can capture code and compute on it like any other type of data. The first way to capture code is with `rlang::expr()`. You can think of `expr()` as returning exactly what you pass in:

```{r}
expr(mean(x, na.rm = TRUE))
expr(10 + 100 + 1000)
```

More formally, captured code is called an __expression__. An expression isn't a single type of object, but is a collective term for any of four types (call, symbol, constant, or pairlist), which you'll learn more about in Chapter \@ref(expressions).

`expr()` lets you capture code that you've typed. You need a different tool to capture code passed to a function because `expr()` doesn't work:

```{r}
capture_it <- function(x) {
  expr(x)
}
capture_it(a + b + c)
```

Here you need to use a function specifically designed to capture user input in a function argument: `enexpr()`. Think of the "en" like in "enrich", `enexpr()` takes a lazily evaluted argument and turns it into an expression:

```{r}
capture_it <- function(x) {
  enexpr(x)
}
capture_it(a + b + c)
```

Once you have captured an expression, you can inspect and modify it. Complex expressions behave much like lists. That means you can modify them using `[[` and `$`:

```{r}
f <- expr(f(x = 1, y = 2))

# Add a new argument
f$z <- 3
f

# Or remove an argument:
f[[2]] <- NULL
f
```

The first element of the call is the function to be called, which means the first argument is in the second position. You'll learn the full details in Section \@ref(calls).

## Code is a tree {#code-tree}

To do more complex manipulation with expressions, you need to fully understand their structure. Behind the scenes, almost every programming language represents code as a tree, often called the __abstract syntax tree__, or AST for short. R is unusual in that you can actually inspect and manipulate this tree.

A very convenient tool for understanding the tree-like structure is `lobstr::ast()`. Given some code, this function displays the underlying tree structure. Function calls form the branches of the tree, and are shown by rectangles. The leaves of the tree are symbols (like `a`) and constants (like `"b"`).

```{r}
lobstr::ast(f(a, "b"))
```

Nested function calls create more deeply branching trees:

```{r}
lobstr::ast(f1(f2(a, b), f3(1, f4(2))))
```

Because all function forms in can be written in prefix form (Section \@ref(prefix-form)), every R expression can be displayed in this way:

```{r}
lobstr::ast(1 + 2 * 3)
```

Displaying the AST in this way is a useful tool for exploring R's grammar, the topic of Section \@ref(grammar).

## Code can generate code {#coding-code}

As well as seeing the tree from code typed by a human, you can also use code to create new trees. There are two main tools: `call2()` and unquoting.

`rlang::call2()` constructs a function call from its components: the function to call, and the arguments to call it with.

```{r}
call2("f", 1, 2, 3)
call2("+", 1, call2("*", 2, 3))
```

This is often convenient to program with, but is a bit clunky for interactive use. An alternative technique is to build complex code trees by combining simpler code trees with a template. `expr()` and `enexpr()` have built-in support for this idea via `!!` (pronounced bang-bang), the __unquote operator__.

<!-- GVW: add a phrase at the end of the 1st sentence below to say __where__ the code tree is inserted. -->

The precise details are the topic of Chapter \@ref(quasiquotation), but basically `!!x` inserts the code tree stored in `x`. This makes it easy to build complex trees from simple fragments:

```{r}
xx <- expr(x + x)
yy <- expr(y + y)

expr(!!xx / !!yy)
```

Notice that the output preserves the operator precedence so we get `(x + x) / (y + y)` not `x + x / y + y` (i.e. `x + (x / y) + y`). This is important to note, particularly if you've been thinking "wouldn't this be easier to do by pasting strings?".

Unquoting gets even more useful when you wrap it up into a function, first using `enexpr()` to capture the user's expression, then `expr()` and `!!` to create an new expression using a template. The example below shows how you can generate an expression that computes the coefficient of variation:

```{r}
cv <- function(var) {
  var <- enexpr(var)
  expr(sd(!!var) / mean(!!var))
}

cv(x)
cv(x + y)
```

(This isn't very useful here, but being able to create this sort of building block is very useful when solving more complex problems.)

Importantly, this works even when given weird variable names:

```{r}
cv(`)`)
```

Dealing with non-syntactic variable names is another good reason to `paste()` when generating R code. You might think this is an esoteric concern, but not worrying about it when generating SQL code in web applications led to SQL injection attacks that have collectively cost billions of dollars.

These techniques become yet more powerful when combined with functional programming. You'll explore these ideas in detail in Section \@ref(expr-case-studies) but the teaser below shows how you could generate a polynomial model specification automatically. At this point, don't worry about fully understanding the code, and instead focus on the input to and output from the function.

```{r, message = FALSE}
library(purrr)

poly <- function(n) {
  i <- seq(2, n)
  xs <- c(1, expr(x), map(i, function(i) expr(I(x^!!i))))
  terms <- reduce(xs, function(l, r) expr(!!l + !!r))
  expr(y ~ !!terms)
}
poly(5)
```

## Evaluation runs code {#eval-intro}

Inspecting and modifying code gives you one set of powerful tools. You get another set of powerful tools when you __evaluate__, i.e. execute or run, an expression. Evaluating an expression requires an environment, which tells R what the symbols mean. You'll learn the details of evaluation in Chapter \@ref(evaluation).

The primary tool for evaluating expressions is `base::eval()`, which takes an expression and an environment:

```{r}
eval(expr(x + y), env(x = 1, y = 10))
eval(expr(x + y), env(x = 2, y = 100))
```

If you omit the environment, `eval` uses the current environment. Here that's the global environment:

```{r}
x <- 10
y <- 100
eval(expr(x + y))
```

One of the big advantages of evaluating code manually is that you can tweak the environment. There are two main reasons to do this:

* To temporarily override functions to implement a domain specific language.
* To add a data mask so you can to refer to variables in a data frame as if
  they are variables in an environment.

## Customising evaluation with functions {#eval-funs}

It's fairly straightforward to understand customising the environment with different variable values. It's less obvious that you can also rebind functions to do different things. This is a big idea that we'll come back to in Chapter \@ref(translation), but the example below shows how powerful it can be. This example evaluates code in a special environment where the basic algebraic operators (`+`, `-`, `*`, `/`) have been overridden to work with strings instead of numbers:

```{r}
string_math <- function(x) {
  e <- env(
    caller_env(),
    `+` = function(x, y) paste0(x, y),
    `*` = function(x, y) strrep(x, y),
    `-` = function(x, y) sub(paste0(y, "$"), "", x),
    `/` = function(x, y) substr(x, 1, nchar(x) / y)
  )

  eval(enexpr(x), e)
}

name <- "Hadley"
string_math("Hi" - "i" + "ello " + name)
string_math("x-" * 3 + "y")
```

dplyr takes this idea to the extreme, running code in an environment that generates SQL for execution in a remote database:

```{r, messasge = FALSE}
library(dplyr)

con <- DBI::dbConnect(RSQLite::SQLite(), filename = ":memory:")
mtcars_db <- copy_to(con, mtcars)

mtcars_db %>%
  filter(cyl > 2) %>%
  select(mpg:hp) %>%
  head(10) %>%
  show_query()

DBI::dbDisconnect(con)
```

## Customising evaluation with data {#eval-data}

Rebinding functions is an extremely powerful technique, but it tends to require a lot of investment. A more immediately practical application is modifying evaluation to look for variables in a data frame instead of an environment. This idea powers the base `subset()` and `transform()` functions, as well as many tidyverse functions like `ggplot2::aes()` and `dplyr::mutate()`. It's possible to use `eval()` for this, but there are a few potential pitfalls (Section \@ref(subset)), so we'll use `rlang::eval_tidy()` instead.

As well as expression and environment, `eval_tidy()` also takes a __data mask__, which is typically a data frame:

```{r}
df <- data.frame(x = 1:5, y = sample(5))
eval_tidy(expr(x + y), df)
```

Evaluating with a data mask is a useful technique for interactive analysis because it allows you to write `x + y` rather than `df$x + df$y`. However, that convenience comes at a cost: ambiguity. In Section \@ref(pronouns) you'll learn how to deal ambiguity using special `.data` and `.env` pronouns.

We can wrap this pattern up into a function by using `enexpr()`. This gives us a function very similar to `base::with()`:

```{r}
with2 <- function(df, expr) {
  eval_tidy(enexpr(expr), df)
}

with2(df, x + y)
```

Unfortunately, however, this function has a subtle bug, and we need a new data structure to deal with it.

## Quosures {#quosure-intro}

To make the problem more obvious, I'm going to modify `with2()`:

```{r}
with2 <- function(df, expr) {
  a <- 1000
  eval_tidy(enexpr(expr), df)
}
```

(The problem occurs without this modification but is subtler and creates error messages that are harder to understand.)

We can see the problem if we attempt to use `with2()` mingling a variable from the data frame and a variable called `a` in the current environment. We want the value of `a` to come from the binding we can see (10), not the binding internal to the function (1000):

```{r}
df <- data.frame(x = 1:3)
a <- 10
with2(df, x + a)
```

That's because we really want to evaluate the captured expression in the environment where it was written (where `a` is 10), not the environment inside of `with2()` (where `a` is 1000).

Fortunately we call solve this problem by using a new data structure: the __quosure__ which bundles an expression with an environment. `eval_tidy()` knows how to work with quosures so all we need to do is switch out `enexpr()` for `enquo()`:

```{r}
with2 <- function(df, expr) {
  a <- 1000
  eval_tidy(enquo(expr), df)
}

with2(df, x + a)
```

Whenever you use a data mask, you must always use `enquo()` instead of `enexpr()`. This is the topic of Chapter \@ref(evaluation).
