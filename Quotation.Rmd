# Quasiquotation

```{r, include = FALSE}
source("common.R")
```

## Introduction

Now that you understand the tree structure of R code, it's time to come back to one of the fundamental ideas that make `expr()` and `ast()` work: quasiquotation. __Quasiquotation__ is made up of two techniques:

* __Quotation__ allows you to capture the AST associated with an argument. 
  As a function author, this gives you a lot of power to influence how
  expressions are evaluated.
  
* __Unquotation__ allows you to selectively evaluate parts of a quoted 
  expression. This is a powerful tool that makes it easy to build up a 
  complex AST from simpler fragments.

The combination of these two ideas makes it easy create functions that combine code written by the function author with code written by the function user, and helps to solve a wide variety of challenging problems. 

Quasiquotation is one of the three component of tidy evaluation, a system used throughout the tidyverse and beyond. You'll learn learn about the other two components (quosures and the data mask) in Chapter \@ref(evaulation). Quasiquotation is useful in its own right but mostly for programming, but tidy evalation is additionally useful for data analysis.

### Outline {-}

### Prerequisites {-}

Make sure you've read the metaprogramming overview in Chapter \@ref(meta) to get a broad overview of the motivation and the basic vocabulary, and you're familiar with the tree structure of expressions as described in Section \@ref(expressions). 

Code-wise, we'll mostly be using the tools from rlang, but at the end of the chapter you'll also see some powerful applications in conjunction with purrr.

```{r setup}
library(rlang)
library(purrr)
```

### Related work {-}
\index{macros} 
\index{fexprs}
 
Quoting functions have deep connections to Lisp __macros__. But macros are usually run at compile-time, which doesn't exist in R, and they always input and output ASTs. @lumley-2001 shows one way you might implement them in R.

Quoting functions are more closely related to Lisp [__fexprs__](http://en.wikipedia.org/wiki/Fexpr), functions where all arguments are quoted by default. These terms are useful to know when looking for related techniques in other programming languages.

## Motivation

We'll start with a simple and concrete example that helps motivate the need for unquoting, and hence quasiquotation. Imagine you're creating a lot of strings by joining together words:

```{r}
paste("Good", "morning", "Hadley")
paste("Good", "afternoon", "Alice")
```

You are sick and tired of writing all those quotes, and instead you just want to use bare words. To that end, you've managed to write the following function:

```{r}
cement <- function(...) {
  args <- ensyms(...)
  paste(purrr::map(args, as_string), collapse = " ")
}

cement(Good, morning, Hadley)
cement(Good, afternoon, Alice)
```

(You'll learn what `ensyms()` does shortly; for now just look at the results.)

Formally, this function __quotes__ the arguments in `...`. You can think of it as automatically putting quotation marks around each argument. That's not precisely true as the intermediate objects it generates are expressions, not strings, but it's a useful approximation for now.

This function is nice because we no longer need to type quotes. The problem, however, comes when we want to use variables. It's easy to use variables with `paste()` as we just don't surround them with quotes:

```{r}
name <- "Hadley"
time <- "morning"

paste("Good", time, name)
```

Obviously this doesn't work with `cement()` because every input is automatically quoted:

```{r}
cement(Good, time, name)
```

We need some way to explicitly __unquote__ the input, to tell `cement()` to remove the automatic quote marks. Here we need `time` and `name` to be treated differently to `Good`. Quasiquotation gives us a standard tool to do so: `!!`, called "unquote", and pronounced bang-bang. `!!` tells a quoting function to drop the implicit quotes:

```{r}
cement(Good, !!time, !!name)
```

It's useful to compare `cement()` and `paste()` directly. `paste()` evaluates its arguments, so we need to quote where needed; `cement()` quotes its arguments, so we need to unquote where needed.

```{r, eval = FALSE}
paste("Good", time, name)
cement(Good, !!time, !!name)
```

### Vocabulary

The distinction between quoted and evaluated arguments is important:

* An __evaluated__ argument obeys R's usual evaluation rules.

* A __quoted__ argument is captured by the function and something unusual 
  will happen.

If you're ever unsure about whether an argument is quoted or evaluated, try executing the code outside of the function. If it doesn't work, then that argument is quoted. For example, you can use this technique to determine that the first argument to `library()` is quoted:

```{r, error = TRUE}
# works
library(MASS)

# fails
MASS
```

Talking about whether an argument is quoted or evaluated is a more precise way of stating whether or not a function uses NSE. I will sometimes use "quoting function" as short-hand for a "function that quotes one or more arguments", but generally, I'll refer to quoted arguments since that is the level at which the difference occurs.

### Theory

Now that you've seen the basic idea, it's time to talk a little bit about the theory. The idea of quasiquotation is an old one. It was first developed by a philosopher, Willard van Orman Quine[^quine], in the early 1940s. It's needed in philosophy because it helps when precisely delineating the use and mention of words, i.e. between the object and the words we use to refer to that object. 

[^quine]: You might be familiar with the name Quine from "quines", computer programs that when run return a copy of their own source code.

Quasiquotation was first used in a programming language, LISP, in the mid-1970s [@bawden-1999]. LISP has one quoting function `` ` ``, and uses `,` for unquoting. Most languages with a LISP heritage behave similarly. For example, racket (`` ` `` and `@`), clojure (`` ` `` and `~`), and julia (`:` and `@`) all have quasiquotation tools that differ only slightly from LISP. 

Many functions in base R quote one or more arguments, but only one uses quasiquotation: `bquote()`, which uses `.()` for unquoting. Unfortunately `bquote()` has had relatively little impact on how R code is written. I think there are three reasons for this:

* It is only easily used with your code; it is hard to apply it to abitrary
  code supplied by a user (i.e. it is most similar to `expr()`, and has no 
  equivalent to `enexpr()`.)
  
* It does not provide an unquote-splice operator that allows you to insert
  multiple arguments, and it doesn't provide a tool that allows you to vary
  the name of a function argument (i.e. it doesn't have `!!!` or `:=`).
  
* It lacks tooling for handling code along with its environment, which is
  crucial for functions that evaluate code in the context of a data frame,
  like `subset()` and friends (i.e. it doesn't provide or use quosures). 

Discovering and remedying these lacks lead to the tidy evaluation framework taught in this book. Despite the newness of tidy eval, I teach it here because it is a rich and powerful theory that, once you master it, makes many hard problems much easier. 

Quasiquotation in R is a little different to LISP and descendants. In LISP there is only one function that does quasiquotation (the quote function), and you must call it explicitly when needed. This makes these languages less ambiguous (because there's a clear code signal that quotation is happening), but is less appropriate for R because quasiquotation is such an important part of DSLs for data analysis.

### Exercises

1.  For each function in the following base R code, identify which arguments
    are quoted and which are evaluated.

    ```{r, results = FALSE}
    library(MASS)
    
    mtcars2 <- subset(mtcars, cyl == 4)
    
    with(mtcars2, sum(vs))
    sum(mtcars2$am)
    
    rm(mtcars2)
    ```

1.  For each function in the following tidyverse code, identify which arguments
    are quoted and which are evaluated.

    ```{r, eval = FALSE}
    library(dplyr)
    library(ggplot2)
    
    by_cyl <- mtcars %>%
      group_by(cyl) %>%
      summarise(mean = mean(mpg))
    
    ggplot(by_cyl, aes(cyl, mean)) + geom_point()
    ```

## Quoting

The first part of quasiquotation is quotation: capturing an expression without evaluating it. There are two components to this: capturing an expression directly, and capturing an expression from a lazily-evaluated function argument. We'll discuss two sets of tools for these two ways of capturing: those provided by rlang, and those provided by base R.

### Capturing expressions

There are four important quoting functions. For interactive exploration, the most important quoting function is `expr()`. It captures its argument exactly as provided:

```{r}
expr(x + y)
expr(1 / 2 / 3)
```

(Remember that white space and comments are not part of the expression, so will not be captured by a quoting function.)

`expr()` is great for interactive exploration, because it captures what you, the developer, typed. It's not so useful inside a function:

```{r}
f1 <- function(x) expr(x)
f1(a + b + c)
```

Instead, we need another function: `enexpr()`. This captures what the caller supplied to the function by looking at the internal promise object that powers lazy evaluation (Section \@ref(promises)).

```{r}
f2 <- function(x) enexpr(x)
f2(a + b + c)
```

To capture multiple arguments (e.g. all arguments in `...`), use `enexprs()`.

```{r}
f <- function(...) enexprs(...)
f(x = 1, y = 10 * z)
```

Finally, `exprs()` is useful interactively to make a list of expressions:

```{r}
exprs(x = x ^ 2, y = y ^ 3, z = z ^ 4)
# shorthand for
# list(x = expr(x ^ 2), y = expr(y ^ 3), z = expr(z ^ 4))
```

There's not much you can do with a list of expressions yet, but we'll see a few techniques later in [case studies](quasi-case-studies): using purrr to work with lists of expressions turns out to be a surprisingly powerful tool.

Use `enexpr()` and `enexprs()` inside a function when you want to capture the expressions supplied as arguments _by the user_ of that function. Use `expr()` and `exprs()` when you want to capture expressions that _you_ supply.

### Capturing symbols

Sometimes you only want to allow the user to specify a variable name, not an arbtirary expression. In this case, you can use `ensym()` or `ensyms()`. These are variants of `enexpr()` and `enexprs()` that check the captured expression is either symbol or a string (which is converted to symbol[^string-symbol]).

[^string-symbol]: This is for compatibility with base R that allows you to provide a string instead of a symbol in many places, e.g. `"x" <- 1`, `"foo"(x, y)`, `c("x" = 1)`.

```{r}
f <- function(...) ensyms(...)
f(x)
f("x")
```

`ensym()` and `ensyms()` throw an error if given anything else:

```{r, error = TRUE}
f(1)
f(x + y)
```

### With base R

The base equivalent of `expr()` is `quote()`:
  
```{r}
quote(x + y)
quote(1 / 2 / 3)
```

It is identical to `expr()` except that it does not support unquoting, so it is a quoting function, not a quasiquoting function.

The base function closest to `enexpr()` is `substitute()`:

```{r}
f3 <- function(x) substitute(x)
f3(x + y + z)
```

You'll most often see it used to capture unevaluated arguments; often in concert with `deparse()` to create labels for output. However, as well as quoting, `substitute()` also does "substitution": if you give it an expression, rather than a symbol, it will substitute in values of symbols defined in the current environment. 

```{r}
f4 <- function(x) substitute(x * 2)
f4(a + b + c)
```

`substitute()` provides a sort of automatic unquoting. I think this makes code hard to understand, because, taken out of context, you can't tell if the goal of `substitute(x + y)` is to replace `x`, or, `y`, or both. If you do want to use `substitute()` for substitution, I recommend that you use the 2nd argument to make your goal clear:

```{r}
substitute(x * y * z, list(x = 10, y = quote(a + b)))
```

The base equivalent to `exprs()` is `alist()`:
  
```{r}
alist(x = 1, y = x + 2)
```

There the equivalent to `enexprs()` is an undocumented feature of `substitute()`[^peter-meilstrup]: you can pretend `...` is a function to capture all arguments in `...`:

```{r}
f <- function(...) as.list(substitute(...()))
f(x = 1, y = 10 * z)
```

[^peter-meilstrup]: Discovered by Peter Meilstrup and described in [R-devel on 2018-08-13](http://r.789695.n4.nabble.com/substitute-on-arguments-in-ellipsis-quot-dot-dot-dot-quot-td4751658.html).

There are two other important base quoting functions that we'll cover elsewhere:

* `bquote()` provides a limited form of quasiquotation, and is discussed in 
  Section \@ref(base-nonquote). 
  
* `~`, the formula, is a quoting function that also captures the environment. 
  It's the inspiration for quosures, the topic of the next chapter, and is 
  discussed in Section \@ref(formulas).

### Summary

When quoting (i.e. capturing code), there are two important distinctions: 

* Is it supplied by the developer of the code or the user of the code?
  i.e. is it fixed or varying, supplied in the body of the function or
  via an argument.
  
* Do you want to capture a single expression or multiple expressions?

This leads to a 2 x 2 table for rlang and base R:

*   rlang:

    |      | Developer | User        | User (symbol only) |
    |------|-----------|-------------|--------------------|
    | One  | `expr()`  | `enexpr()`  | `ensym()`          |
    | Many | `exprs()` | `enexprs()` | `ensyms()`         |

*   from base R:

    |      | Developer | User                        |
    |------|-----------|-----------------------------|
    | One  | `quote()` | `substitute()`              |
    | Many | `alist()` | `eval(substitute(alist()))` |

### Exercises

1.  What does the following command return? What information is lost? Why?

    ```{r, eval = FALSE}
    expr({
      x +              y # comment  
    })
    ```

1.  Compare and contrast the following two functions. Can you predict the
    output before running them?

    ```{r, results = FALSE}
    f1 <- function(x, y) {
      exprs(x = x, y = y)
    }
    f2 <- function(x, y) {
      enexprs(x = x, y = y)
    }
    f1(a + b, c + d)
    f2(a + b, c + d)
    ```

1.  What happens if you try to use `enexpr()` with an expression (i.e. 
    `enexpr(x + y)` ? What happens if `enexpr()` is passed a missing argument?

1.  How are `exprs(a)` and `exprs(a = )` different? Think about both the
    input and the output.

1.  The documentation for `substitute()` says:

    > Substitution takes place by examining each component of the parse tree 
    > as follows: 
    > 
    > * If it is not a bound symbol in `env`, it is unchanged. 
    > * If it is a promise object (i.e., a formal argument to a function) 
    >   the expression slot of the promise replaces the symbol. 
    > * If it is an ordinary variable, its value is substituted;
    > * Unless `env` is .GlobalEnv in which case the symbol is left 
    >   unchanged.
    
    Create four examples that illustrate each of the different cases.

## Unquoting

So far, you've only seen relatively small advantages of rlang quoting functions over the base R quoting functions: they have a more consistent naming scheme. The big difference is that rlang quoting functions are actually __quasiquoting__ functions, because they support unquoting with `!!` (called "unquote", and pronounced bang-bang).

Unquoting allows you to selectively execute, or evaluate, parts of the expression that would otherwise be quoted, and it effectively allows you to merge together ASTs using a template AST.

Unquoting is one inverse of quoting. It happens inside calls to `expr()`, so that `expr(!!x)` is equivalent to `x`. In Chapter \@ref(evaluation), you'll learn about another inverse, evaluation. Evaluation happens outside calls to `expr()`, so that `eval(expr(x))` is equivalent to `x`.

### Unquoting one argument

To unquote a single element, use `!!`, a one-to-one replacement. It takes a single expression and inlines the AST at the location of the `!!`. 

```{r}
x <- expr(a + b + c)
expr(f(!!x, y))
```

I think this is easiest to understand with a diagram:

```{r, echo = FALSE, out.width = NULL}
knitr::include_graphics("diagrams/quotation/bang-bang.png")
```

`!!` introduce placeholders in the AST, illustrated with dotted borders. Here the placeholder `x` is replaced by an AST, illustrated by a dotted connection.

As well as call objects, `!!` also works with symbols and constants:

```{r}
a <- sym("y")
b <- 1
expr(f(!!a, !!b))
```
```{r, echo = FALSE, out.width = NULL}
knitr::include_graphics("diagrams/quotation/simple.png")
```

Because it works with expressions, `!!` respects operator precedence:

```{r}
x1 <- expr(x + 1)
x2 <- expr(x + 2)

expr(!!x1 / !!x2)
```
```{r, echo = FALSE, out.width = NULL}
knitr::include_graphics("diagrams/quotation/infix.png")
```

If we simply pasted the text of the expressions together, we'd end up with `x + 1 / x + 2`, which has a very different AST:

```{r, echo = FALSE, out.width = NULL}
knitr::include_graphics("diagrams/quotation/infix-bad.png")
```

### Unquoting a function

`!!` is most commonly used to replace the arguments to a function, but you can also use it to replace the function itself. The only challenge here is operator precedence: `expr(!!f(x, y))` unquotes the result of `f(x, y)`, so you need to use `expr((!!f)(x, y))`.

```{r}
f <- expr(foo)
expr((!!f)(x, y, z))
```

This also works when `f` is itself a call:

```{r}
f <- expr(pkg::foo)
expr((!!f)(x, y, z))
```

```{r, echo = FALSE, out.width = NULL}
knitr::include_graphics("diagrams/quotation/fun.png")
```

Because of the large number of parentheses involved, it can be more clear to use `rlang::call2()`:

```{r}
f <- expr(pkg::foo)
call2(f, expr(x), expr(y), expr(z))
```

### Unquoting a missing argument {#unquote-missing}

Very occasionally it is useful to unquote a missing argument (Section \@ref(empty-symbol)), but the naive approach doesn't work:

```{r, error = TRUE}
arg <- missing_arg()
expr(foo(!!arg, !!arg))
```

You can work around this with the `maybe_missing()` helper:

```{r}
expr(foo(!!maybe_missing(arg), !!maybe_missing(arg)))
```

### Unquoting many arguments

`!!` is a one-to-one replacement. `!!!` (called "unquote-splice", and pronounced bang-bang-bang) is a one-to-many replacement. It takes a list of expressions and inserts them at the location of the `!!!`:

```{r}
xs <- exprs(1, a, -b)
expr(f(!!!xs, y))
```

```{r, echo = FALSE, out.width = NULL}
knitr::include_graphics("diagrams/quotation/bang-bang-bang.png")
```

`!!!` can be used in any rlang function that takes `...` regardless of whether or not it's a quoting function. We'll come back to this in Section \@ref(tidy-dots).

```{r}
f <- expr(pkg::foo)
call2(f, !!!exprs(x, y, z))
```

### The polite fiction of `!!`

So far we have acted as if `!!` and `!!!` are regular prefix operators like `+` , `-`, and `!`. They're not. Instead, from R's perspective, `!!` and `!!!` are simply the repeated application of `!`: 

```{r}
!!TRUE
!!!TRUE
```

`!!` and `!!!` have special behaviour inside all quoting functions powered by rlang, where they behave like real operators. We chose `!!` and `!!!` as the best compromise: 

* The are visually strong and don't look like existing syntax. When you 
  see `!!x` or `!!!x` it's clear that something unusual is happenning.
  
* It overrides a rarely used piece of syntax, as double negation is not a
  common pattern in R[^js-double-neg]. If you you do need it, you can just
  add parentheses `!(!x)`.

[^js-double-neg]: Unlike, say, javascript, where `!!x` is a commonly used shortcut to convert an integer into a logical.

The unquoting operators are given precedence equal to unary `+` and `-`, not `!`. We do this because the operator precedence for `!` is surprisingly low: it has lower precedence than that of the binary algebraic and logical operators. Most of the time this doesn't matter as it is unusual to mix `!` and binary operators (e.g. you typically would not write `!x + y` or `!x > y`). However, expressions like `!!x + !!y` are not uncommon when unquoting, and requiring explicit parentheses, `(!!x) + (!!y)`, feels onerous. For this reason, rlang manipulates the AST to give the unquoting operators a higher, more natural, precedence.

The biggest downside[^bang-bang-print] to using a fake operator is that you might get silent errors when misusing `!!` outside of quasiquoting functions. Most of the time this is not an issue because `!!` is typically used to unquote expressions or quosures. Since expressions are not supported by the negation operator, you will get an argument type error in this case:

```{r, error = TRUE}
x <- quote(variable)
!!x
```

However be extra careful when unquoting numeric values that can be negated silently:

```{r}
x <- 100
with(mtcars, cyl + !!x)
```

Instead of adding the value of `x` to `cyl` as intended, we have in fact added the double negation of `x`:

```{r}
!x
!!x
```

[^bang-bang-print]: Prior to R 3.5.1, there was another major downside: the R deparser treated `!!x` as `!(!x)`. This is why in old versions of R you might see extra parentheses when printing expressions. The good news is that these parentheses are not real and can be safely ignored most of the time. The bad news is that they will become real if you reparse that printed output to R code. These roundtripped functions will not work as expected since `!(!x)` does not unquote anything.

Given these drawbacks, you might wonder why rlang does not use a regular function call. Indeed, early versions of rlang used `UQ()` and `UQS()` instead of `!!` and `!!!`. However, these looked like regular function calls, rather than special syntactic operators, and evoked a misleading mental model, which made them harder to use correctly.

### Non-standard ASTs {#non-standard-ast}

With unquoting, it is easy to create non-standard ASTs, i.e. ASTs that contain components that are not expressions. (It is also possible to create non-standard ASTs by directly manipulating the underlying objects, but it's harder to do so accidentally.) These are valid, and occasionally useful, but their correct use is beyond the scope of this book. However, it's important to learn about them because they can be deparsed, and hence printed, in misleading ways. 

For example, if you inline more complex objects, their attributes are not printed. This can lead to confusing output:

```{r}
x1 <- expr(class(!!data.frame(x = 10)))
x1
lobstr::ast(!!x1)
eval(x1)
```

In other cases, R will print parentheses that do not exist in the AST:

```{r}
y2 <- expr(2 + 3)
x2 <- expr(1 + !!y2)
x2
lobstr::ast(!!x2)
```

And finally, R will display integer sequences as if they were generated with `:`.

```{r}
x3 <- expr(f(!!c(1L, 2L, 3L, 4L, 5L)))
x3
lobstr::ast(!!x3)
```

In general, if you're ever confused about what is actually in the AST, use `lobstr::ast()`.

### Exercises

1.  Given the following components:

    ```{r}
    xy <- expr(x + y)
    xz <- expr(x + z)
    yz <- expr(y + z)
    abc <- exprs(a, b, c)
    ```
    
    Use quasiquotation to construct the following calls:
    
    ```{r, eval = FALSE}
    (x + y) / (y + z)
    -(x + z) ^ (y + z)
    (x + y) + (y + z) - (x + y)
    atan2(x + y, y + z)
    sum(x + y, x + y, y + z)
    sum(a, b, c)
    mean(c(a, b, c), na.rm = TRUE)
    foo(a = x + y, b = y + z)
    ```

1.  Explain why both `!0 + !0` and `!1 + !1` return `FALSE` while
    `!0 + !1` returns `TRUE`.

1.  Base functions `match.fun()`, `page()`, and `ls()` all try to
    automatically determine whether you want standard or non-standard
    evaluation. Each uses a different approach. Figure out the essence
    of each approach by reading the source code, then compare and contrast
    the techniques.

1.  The following two calls print the same, but are actually different:

    ```{r}
    (a <- expr(mean(1:10)))
    (b <- expr(mean(!!(1:10))))
    identical(a, b)
    ```

    What's the difference? Which one is more natural?

## Non-quoting in base R {#base-nonquote}

Base R has one function that implements quasiquotation: `bquote()`. It uses `.()` for unquoting:

```{r}
xyz <- bquote((x + y + z))
bquote(-.(xyz) / 2)
```

But `bquote()` isn't used in any other function in base R and instead functions that quote an argument use some other technique to allow indirect specification. Rather than using use unquoting all base R approaches selectively turn quoting off, so I call them __non-quoting__ techniques.

```{r, include = FALSE}
call <- names(pryr::find_uses("package:base", "match.call"))
subs <- names(pryr::find_uses("package:base", "substitute"))
eval <- names(pryr::find_uses("package:base", "eval"))

intersect(subs, eval)
```

There are four basic forms seen in base R:

*   A pair of quoting and non-quoting functions. For example, `$` has two 
    arguments, and the second argument is quoted. This is easier to see if you 
    write in prefix form: `mtcars$cyl` is equivalent to `` `$`(mtcars, cyl) ``. 
    If you want to refer to a variable indirectly, you use `[[`, as it 
    takes the name of a variable as a string.
      
    ```{r}
    x <- list(var = 1, y = 2)
    var <- "y"
    
    x$var
    x[[var]]
    ```
    
    There are three quoting functions closely related to `$`: `subset()`,
    `transform()`, and `with()`. These seen as wrappers around `$` suitable 
    for interactive use so they all have the same non-quoting alternative: `[`
  
    `<-`/`assign()` and `::`/`getExportedValue()` work similarly to `$`/`[`.

*   A pair of quoting and non-quoting arguments. For example, `rm()` allows 
    you to provide bare variable names in `...`, or a character vector of
    variable names in `list`:

    ```{r}
    x <- 1
    rm(x)

    y <- 2
    vars <- c("y", "vars")
    rm(list = vars)
    ```
    
    `data()` and `save()` work similarly.

*   An argument that controls whether a different argument is quoting or 
    non-quoting. For example, in `library()`, the `character.only` argument
    controls the quoting behaviour of the first argument, `package`:
    
    ```{r, message = FALSE}
    library(MASS)
    
    pkg <- "MASS"
    library(pkg, character.only = TRUE)
    ```
    
    `demo()`, `detach()`, `example()`, and `require()` work similarly.

*   Quoting if evaluation fails. For example, the first argument to `help()`
    is non-quoting if it evaluates to a string; if evaluation fails, the
    first argument is quoted.

    ```{r, eval = FALSE}
    # Shows help for var
    help(var)
    
    var <- "mean"
    # Shows help for mean
    help(var)
    
    var <- 10
    # Shows help for var
    help(var)
    ```
    
    `ls()`, `page()`, and `match.fun()` work similarly. 

Another important class of quoting functions are the base modelling and plotting functions, which follow the so-called standard non-standard evaluation rules: <http://developer.r-project.org/nonstandard-eval.pdf>. For example, `lm()` quotes the `weight` and `subset` arguments, and when used with a formula argument, the plotting function quotes the aesthetic arguments (`col`, `cex`, etc):

```{r}
palette(RColorBrewer::brewer.pal(3, "Set1"))
plot(
  data = iris, 
  Sepal.Length ~ Petal.Length, col = Species, 
  pch = 20, cex = 2
)
```

These functions have no built-in options for indirect specification, but you'll learn how to simulate unquoting in Section \@ref(base-unquote).


## Case studies 

To make the ideas of quasiquotation concrete, this section contains a few smaller case studies that show how you can use it to solve real problems. Some of the case studies also use purrr: I find the combination of quasiquotation and functional programming to be particularly elegant.

Most users of quasiquotation will not involve `expr()` or `exprs()` but will instead involve a function that calls `enexpr()` or `enexprs()`. You should be able tell if a function uses quasiquotation because the documentation will mention it, and consequently if you use `enexpr()` in a documented function, make sure to mention quasiquotation.

This technique allows you to write functions that wrap around quasiquotation functions with a simple pattern: quote with `enexpr()` then unquote with `!!`:

```{r}
cv <- function(x) {
  x <- enexpr(x)
  expr(sd(!!x) / mean(!!x))
}

cv(x + y)
```

### `lobstr::ast()`

Quasiquotation allows us to solve an annoying problem with `lobstr::ast()`: what happens if we've already captured the expression?

```{r}
z <- expr(foo(x, y))
lobstr::ast(z)
```

Because `ast()` supports quasiquotation, we can use `!!`:

```{r}
lobstr::ast(!!z)
```

### Map-reduce to generate code

Quasiquotation gives us powerful tools for generating code, particularly when combined with `purrr::map()` and `purr::reduce()`. For example, assume you have a linear model specified by the following coefficients:

```{r}
intercept <- 10
coefs <- c(x1 = 5, x2 = -4)
```

And you want to convert it into an expression like `10 + (5 * x1) + (-4 * x2)`. The first thing we need to do is turn the character names vector into a list of symbols. `rlang::syms()` is designed precisely for this case:

```{r}
coef_sym <- syms(names(coefs))
coef_sym
```

Next we need to combine each variable name with its coefficient. We can do this by combining `rlang::expr()` with `purrr::map2()`:

```{r}
summands <- map2(coef_sym, coefs, ~ expr((!!.x * !!.y)))
summands
```

In this case, the intercept is also a part of the sum, although it doesn't involve a multiplication. We can just add it to the start of the `summands` vector:

```{r}
summands <- c(intercept, summands)
summands
```

Finally, we need to reduce the individual terms into a single sum by adding the pieces together:

```{r}
eq <- reduce(summands, ~ expr(!!.x + !!.y))
eq
```

We could make this even more general by allowing the user to supply the name of the coefficient, and instead of assuming many different variables, index into a single one.

```{r}
var <- expr(y)
coef_sym <- map(seq_along(coefs), ~ expr((!!var)[[!!.x]]))
coef_sym
```

And finish by wrapping this up into a function:

```{r}
linear <- function(var, val) {
  var <- ensym(var)
  coef_name <- map(seq_along(val[-1]), ~ expr((!!var)[[!!.x]]))

  summands <- map2(coefs, coef_name, ~ expr((!!.x * !!.y)))
  summands <- c(val[[1]], summands)

  reduce(summands, ~ expr(!!.x + !!.y))
}

linear(x, c(10, 5, -4))
```

Note the use of `ensym()`. We want the user to supply the name of a single variable, not a more complex expression.

We could even make this into a function-generating function:

```{r}
linear_fun <- function(var, val) {
  var <- ensym(var)
  
  new_function(
    exprs(!!var := !!missing_arg()), 
    linear(!!var, val),
    caller_env()
  )
}
linear_fun(x, c(10, 5, -4))
```

### Slicing an array

An occassionally useful tool missing from base R is the ability to extract a slice of an array given a dimension and an index. For example, we'd like to write `slice(x, 2, 1)` to extract the first slice along the second dimension, which you can write as `x[, 1, ]`. This is a moderately challenging problem because it requires working with missing arguments. 

We'll need to generate a call with multiple missing arguments. Fortunately that's easy with `rep()` and `missing_arg()`. Once we have those arguments, we can unquote-splice them into a call:

```{r}
indices <- rep(list(missing_arg()), 3)
expr(x[!!!indices])
```

Then we use subset-assignment to insert the index in the desired position:

```{r}
indices[[2]] <- 1
expr(x[!!!indices])
```

We then wrap this into a function, using a couple of `stopifnot()`s to make the interface clear:

```{r}
slice <- function(x, along, index) {
  stopifnot(length(along) == 1)
  stopifnot(length(index) == 1)
    
  nd <- length(dim(x))
  indices <- rep(list(missing_arg()), nd)
  indices[[along]] <- index
  
  expr(x[!!!indices])
}

x <- array(sample(30), c(5, 2, 3))
slice(x, 1, 3)
slice(x, 2, 2)
slice(x, 3, 1)
```

A real `slice()` would evaluate the generated call, but here I think it's more illuminating to see the code that's generated, as that's the hard part of the challenge.

### Creating functions {#new-function}
\index{anaphoric functions} \index{functions!anaphoric}

Another powerful application of quotation is creating functions "by hand", using  `rlang::new_function()`. It's a function that create a function from its three components (Section \@ref(function-components)) arguments, body, and (optionally) environment:

```{r}
new_function(
  exprs(x = , y = ), 
  expr({x + y})
)
```

One use of `new_function()` is as an alternative to function factories with scalar or symbol arguments. For example, we could write a function that generates functions that raise a function to the power of a number. 
 
```{r}
power <- function(exponent) {
  new_function(
    exprs(x = ), 
    expr({
      x ^ !!exponent
    }), 
    caller_env()
  )
}
power(0.5)
```

(Note that `power()` is not a quotating function. It inlines the _value_ of `exponent`, not the expression that generates it.)

Another application of `new_function()` for functions that work like `graphics::curve()`. `curve()` allows you to plot a mathematical expression, without creating a function:

```{r curve-demo, fig.width = 3.5, fig.height = 2.5, small_mar = TRUE}
curve(sin(exp(4 * x)), n = 1000)
```

Here `x` is a pronoun: it doesn't represent a single concrete value, but is instead a placeholder that varies over the range of the plot. One way to implement `curve()` is to turn that expression into a function with a single argument, `x`, then call that function:

```{r curve2, fig.show="hide"}
curve2 <- function(expr, xlim = c(0, 1), n = 100) {
  expr <- enexpr(expr)
  f <- new_function(exprs(x = ), expr)
  
  x <- seq(xlim[1], xlim[2], length = n)
  y <- f(x)

  plot(x, y, type = "l", ylab = expr_text(expr))
}
curve2(sin(exp(4 * x)), n = 1000)
```

Functions, like `curve()`, that use an expression containing a pronoun are known as __anaphoric__ functions[^anaphora].

[^anaphora]: Anaphoric comes from the linguistics term "anaphora", an expression that is context dependent. Anaphoric functions are found in [Arc](http://www.arcfn.com/doc/anaphoric.html) (a LISP like language), [Perl](http://www.perlmonks.org/index.pl?node_id=666047), and [Clojure](http://amalloy.hubpages.com/hub/Unhygenic-anaphoric-Clojure-macros-for-fun-and-profit).

### Exercises

1.  In the linear-model example, we could replace the `expr()` in 
    `reduce(summands, ~ expr(!!.x + !!.y))` with `call2()`:
    `reduce(summands, call2, "+")`. Compare and constrast the two 
    approaches. Which do you think is easier to read?

1.  Re-implement the Box-Cox transform defined below using unquoting and
    `new_function()`:

    ```{r}
    bc <- function(lambda) {
      if (lambda == 0) {
        function(x) log(x)
      } else {
        function(x) (x ^ lambda - 1) / lambda
      }
    }
    ```

1.  Re-implement the simple `compose()` defined below using quasiquotation and 
    `new_function()`:
    
    ```{r}
    compose <- function(f, g) {
      function(...) f(g(...))
    }
    ```

## Dot-dot-dot (`...`) {#tidy-dots}

Quasiquotation ensures that every quoted argument has an escape hatch that allows the user to unquote, or evaluate, selected components, if needed. A similar and related need arises with functions that take arbitrary additional arguments with `...`. Take the following two motivating problems:

*   What do you do if the elements you want to put in `...` are already stored 
    in a list? For example, imagine you have a list of data frames that 
    you want to `rbind()` together:
    
    ```{r}
    dfs <- list(
      a = data.frame(x = 1, y = 2),
      b = data.frame(x = 3, y = 4)
    )
    ```
    
    You could solve this specific case with `rbind(dfs$a, df$b)`, but how
    do you generalise that solution to a list of arbitrary length?

*   What do you do if you want to supply the argument name indirectly? For 
    example, imagine you want to create a single column data frame where 
    the name of the column is specified in a variable:
    
    ```{r}
    var <- "x"
    val <- c(4, 3, 9)
    ```
    
    In this case, you could create a data frame and then change names
    (i.e. `setNames(data.frame(val), var)`), but this feels inelegant.
    How can we do better?

### Base R: `do.call()`

Base R provides swiss-army knife to solve these problems: `do.call()`. `do.call()` has two main arguments. The first argument, `what`, gives a function to call. The second argument, `args`, is a list of arguments to pass to that function, and so `do.call("f", list(x, y, z))` is equivalent to `f(x, y, z)`.

*   `do.call()` gives a straightforward solution to `rbind()`ing together many 
    data frames:

    ```{r}
    do.call("rbind", dfs)
    ```

*   With a little more work, we can use `do.call()` to solve the second problem. 
    We first create a list of arguments, then name that, then use `do.call()`:
    
    ```{r}
    args <- list(val)
    names(args) <- var
    
    do.call("data.frame", args)
    ```

Some base functions provide a helper so that you don't need to use `do.call()`. One technique is to take `...` and a single unnamed argument that is a list, making `f(list(x, y, z))` equivalent to `f(x, y, z)`. Base functions that use this technique include `interaction()`, `expand.grid()`, `options()`, and `par()`. The implementation looks something like this:

```{r}
f <- function(...) {
  dots <- list(...)
  if (length(dots) == 1 && is.list(dots[[1]])) {
    dots <- dots[[1]]
  }
  
  # Do something
  ...
}
```

A related technique is used in the `RCurl::getURL()` function written by Duncan Temple Lang. `getURL()` takes both `...` and `.opts` which are concatenated together.  This is useful when writing functions to call web APIs because you often have some options that need to be passed to every request. You put these in a common list and pass to `.opts`, saving `...` for the options unique for a given call. At the time I discovered it, I found this technique particularly compelling so you can see it used throughout the tidyverse. Now, however, I prefer the approach described next.

```{r}
f <- function(..., .dots) {
  dots <- c(list(...), .dots)
  # Do something
}
```

### Tidy eval: `list2()`

The tidyverse solves these problems in a different way to base R, by drawing parallel to quasiquotation:

*   Row-binding multiple data frames is like unquote-splicing: we want to inline
    individual elements of the list into the call:

    ```{r}
    dplyr::bind_rows(!!!dfs)
    ```
    
    When used in this context, the behaviour of `!!!` is known as spatting in 
    Ruby, Go, PHP, and Julia. It is closely related to `*args` (star-args) and
    `**kwarg` (star-star-kwargs) in Python, which are sometimes called argument
    unpacking. 

*   The second problem is like unquoting on the LHS of `=`: rather than 
    interpreting `var` literally, we want to use the value stored in the variable 
    called `var`:

    ```{r}
    tibble::tibble(!!var := val)
    ```

    Note the use of `:=` (pronounced colon-equals) rather than `=`. Unfortunately 
    we need this new operation because R's grammar does not allow expressions as
    argument names:
    
    ```{r, eval = FALSE}
    tibble::tibble(!!var = value)
    #> Error: unexpected '=' in "tibble::tibble(!!var ="
    ```
    
    `:=` is like a vestigial organ: it's recognised by R's parser, but it doesn't
    have any code associated with it. It looks like an `=` but allows 
    expressions on either side, making it a more flexible alternative to `=`. 
    It is used in data.table for similar reasons.

Both `dplyr::bind_rows()` and `tibble::tibble()` are powered by `rlang::list2(...)`. This function is very similar to `list(...)`, but it understands `!!!` and `!!`. If you want to take advantage of this behaviour in your own function, all you need to do is use `list2()` in your own code. For example, imagine you want to make a version of `structure()` that understands `!!!` and `!!`. We'll call it `set_attr()`:

```{r}
set_attr <- function(.x, ...) {
  attr <- rlang::list2(...)
  attributes(.x) <- attr
  .x
}

attrs <- list(x = 1, y = 2)
attr_name <- "z"

1:10 %>%
  set_attr(w = 0, !!!attrs, !!attr_name := 3) %>% 
  str()
```

Note that we call the first argument `.x`: whenever you use `...` to take arbitrary data, it's good practice to give the other argument names a `.` prefix. This eliminates any ambiguity about who owns the argument, and in this case makes it possible to set the `x` attribute.

`list2()` provides one other handy feature: by default it will ignore any empty arguments at the end. This is useful in functions like `tibble::tibble()` because it means that you can easily change the order of variables without worrying about the final comma:

```{r, results = FALSE}
# Can easily move x to first entry:
tibble::tibble(
  y = 1:5,
  z = 3:-1,
  x = 5:1,
)

# Need to remove comma from z and add comma to x
data.frame(
  y = 1:5,
  z = 3:-1,
  x = 5:1
)
```

As well as `list2()`, rlang also provides `lgl()`, `int()`, `dbl()`, and `chr()` which create atomic vectors in the same way.

### `rlang::exec()`

One useful application of `list2()` is `exec()`, which you can think of as a wrapper around `list2()` and `do.call()`:

```{r, eval = FALSE}
exec <- function(f, ..., .env = caller_env()) {
  args <- list2(...)
  do.call(f, args, envir = .env)
}
```

This makes it easy to call functions with some arguments supplied  directly (in ...) and others indirectly (in a list):

```{r}
# Directly
exec("mean", x = 1:10, na.rm = TRUE, trim = 0.1)

# Indirectly
args <- list(x = 1:10, na.rm = TRUE, trim = 0.1)
exec("mean", !!!args)

# Mixed
params <- list(na.rm = TRUE, trim = 0.1)
exec("mean", x = 1:10, !!!params)
```

And also makes it possible to supply argument names indirectly:

```{r}
arg_name <- "na.rm"
arg_val <- TRUE
exec("mean", 1:10, !!arg_name := arg_val)
```

And finally, it's useful if you have a vector of function names or a list of functions that you want to call with the same arguments:

```{r}
x <- c(runif(10), NA)
funs <- c("mean", "median", "sd")

purrr:::map_dbl(funs, exec, x, na.rm = TRUE)
```

`exec()` is closely related to `call2()`; where `call2()` returns an expression, `exec()` evaluates it. 

### Exercises

1.  Carefully read the source code for `interaction()`, `expand.grid()`, and 
    `par()`.  Compare and contrast the techniques they use for switching 
    between dots and list behaviour.

1.  Explain the problem with this definition of `set_attr()`
    
    ```{r, error = TRUE}
    set_attr <- function(x, ...) {
      attr <- rlang::list2(...)
      attributes(x) <- attr
      x
    }
    set_attr(1:10, x = 10)
    ```
